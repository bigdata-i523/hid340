{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 367\n",
      "37 344\n",
      "33 333\n",
      "38 331\n",
      "23 325\n",
      "24 322\n",
      "33 319\n",
      "20 319\n",
      "24 316\n",
      "21 319\n",
      "22 315\n",
      "26 314\n",
      "23 311\n",
      "21 317\n",
      "22 308\n",
      "28 313\n",
      "19 314\n",
      "25 305\n",
      "23 309\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d16f0b5f6a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# Net input of hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;31m# Activation of hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  7 03:27:25 2017\n",
    "\n",
    "Based on the supervised gradident-based learning algorithm specified by \n",
    "Reyes-Galaviz et al. (2017).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_count = 8 \n",
    "hidden_count = 5\n",
    "output_count = 1\n",
    "\n",
    "eta = 0.4\n",
    "\n",
    "data = np.load(\"record_pairs.npy\", encoding=\"latin1\")\n",
    "data2 = np.nan_to_num(data)\n",
    "\n",
    "# Quality thresholds\n",
    "tau_1 = 0.5\n",
    "tau_2 = 0.5\n",
    "\n",
    "# The MLP model has 8 inputs and 5 nodes in the hidden layer. It follows \n",
    "# the Model 2 setup presented by Reyes-Galaviz et al. Hidden nodes aggregate\n",
    "# values calculated by running each of 8 comparison functions over 5 data\n",
    "# fields (date, ISBN, title, publisher, creator/contributor)\n",
    "r = np.random.randn(input_count, hidden_count)\n",
    "w = np.random.randn(hidden_count, output_count)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def activate(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "# Partial derivatives for output layer\n",
    "\n",
    "# MSE\n",
    "#def E_total(c, s):\n",
    "#    if c == 0:\n",
    "#        return 0.5 * np.sum(tau_1 - s)**2\n",
    "#    else:\n",
    "#        return 0.5 * np.sum(tau_2 - s)**2\n",
    "    \n",
    "#def dQ_ds(c, s):\n",
    "#    if c == 0:\n",
    "#        return -(tau_1 - np.sum(s))\n",
    "#    else:\n",
    "#        return -(tau_2 - np.sum(s))             \n",
    "    \n",
    "def dQ_ds(c, data):              \n",
    "    if c == 0:            \n",
    "        if np.sum(data) > tau_1:\n",
    "            data = 2 * data\n",
    "            return data\n",
    "    else:        \n",
    "        if np.sum(data) < tau_2:\n",
    "            data = 2 * (data - 1)\n",
    "            return data\n",
    "    return data\n",
    "\n",
    "def ds_dl(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def dy_dp(y):\n",
    "    return y * (1 - y)\n",
    " \n",
    "output = []\n",
    "tally = []\n",
    "training = data[0:1960]\n",
    "\n",
    "# Iterations for training model\n",
    "for i in range(1000):      \n",
    "      \n",
    "    training = np.random.permutation(training)    \n",
    "    \n",
    "    for t in training:    \n",
    "        t2 = np.nan_to_num(t)\n",
    "        if t2.shape[0] != 0:\n",
    "            \n",
    "            for u in t2:                                     \n",
    "                c = u[:, :][5][0]\n",
    "            \n",
    "                u2 = u[:5, :]\n",
    "            \n",
    "                # Net input of hidden layer\n",
    "                p = np.dot(u2, r)        \n",
    "                \n",
    "                # Activation of hidden layer\n",
    "                y = activate(p)\n",
    "                \n",
    "                # Chain of partial derivatives for Model 2               \n",
    "                \n",
    "                # Net input of output node\n",
    "                l = np.dot(y, w)        \n",
    "                \n",
    "                # Activation of output node\n",
    "                s = activate(l)   \n",
    "                \n",
    "                dE_o = dQ_ds(c, s)\n",
    "                \n",
    "                dE_h = np.dot(dE_o, w.T)\n",
    "                \n",
    "                dQ_dw = eta * np.dot(y.T, dE_o * ds_dl(s))\n",
    "                                     \n",
    "                dQ_dr = eta * np.dot(u2.T, dE_h * dy_dp(y))        \n",
    "                \n",
    "                r -= dQ_dr\n",
    "                w -= dQ_dw\n",
    "                \n",
    "                output.append([np.sum(s), c])\n",
    "                \n",
    "                \n",
    "            result = np.array([output])\n",
    "           \n",
    "            \n",
    "            \n",
    "            f = result\n",
    "            if len(f) > 0:              \n",
    "                f2 = result[:, :, 1] == 0\n",
    "                f3 = result[:, :, 1] == 1\n",
    "                f4 = result[:, :, 0] > 0.5\n",
    "                f5 = result[:, :, 0] < 0.5\n",
    "                  \n",
    "                #print(len(f[f2 & f4]), len(f[f3 & f5]))\n",
    "                tally.append([len(f[f2 & f4]), len(f[f3 & f5])])\n",
    "            \n",
    "        r_final = r\n",
    "        w_final = w\n",
    "            \n",
    "        output = []\n",
    "        result = []\n",
    "\n",
    "    print(np.sum(np.array([tally])[:, :, 0]), np.sum(np.array([tally])[:, :, 1]))\n",
    "    tally = []\n",
    "        #np.savetxt(\"training_output.txt\", np.array([output]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
