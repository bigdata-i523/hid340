{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 379\n",
      "34 349\n",
      "23 331\n",
      "22 324\n",
      "20 318\n",
      "30 322\n",
      "25 313\n",
      "19 311\n",
      "27 313\n",
      "19 304\n",
      "18 307\n",
      "20 307\n",
      "23 306\n",
      "20 305\n",
      "16 304\n",
      "22 303\n",
      "20 301\n",
      "19 304\n",
      "18 302\n",
      "20 301\n",
      "19 301\n",
      "16 303\n",
      "17 301\n",
      "20 299\n",
      "24 303\n",
      "20 299\n",
      "17 300\n",
      "20 295\n",
      "24 303\n",
      "17 300\n",
      "20 300\n",
      "26 301\n",
      "21 297\n",
      "15 299\n",
      "21 298\n",
      "22 301\n",
      "13 294\n",
      "17 300\n",
      "25 302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7e68413dd271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Net input of output node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Activation of output node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  7 03:27:25 2017\n",
    "\n",
    "Based on the supervised gradident-based learning algorithm specified by \n",
    "Reyes-Galaviz et al. (2017).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_count = 8 \n",
    "hidden_count = 5\n",
    "output_count = 1\n",
    "\n",
    "eta = 0.02\n",
    "\n",
    "data = np.load(\"record_pairs.npy\", encoding=\"latin1\")\n",
    "data2 = np.nan_to_num(data)\n",
    "\n",
    "# Quality thresholds\n",
    "tau_1 = 0.01\n",
    "tau_2 = 0.99\n",
    "\n",
    "# The MLP model has 8 inputs and 5 nodes in the hidden layer. It follows \n",
    "# the Model 2 setup presented by Reyes-Galaviz et al. Hidden nodes aggregate\n",
    "# values calculated by running each of 8 comparison functions over 5 data\n",
    "# fields (date, ISBN, title, publisher, creator/contributor)\n",
    "r = np.random.randn(input_count, hidden_count)\n",
    "w = np.random.randn(hidden_count, output_count)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def activate(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "# Partial derivatives for output layer\n",
    "\n",
    "# MSE\n",
    "#def E_total(c, s):\n",
    "#    if c == 0:\n",
    "#        return 0.5 * np.sum(tau_1 - s)**2\n",
    "#    else:\n",
    "#        return 0.5 * np.sum(tau_2 - s)**2\n",
    "    \n",
    "#def dQ_ds(c, s):\n",
    "#    if c == 0:\n",
    "#        return -(tau_1 - np.sum(s))\n",
    "#    else:\n",
    "#        return -(tau_2 - np.sum(s))             \n",
    "    \n",
    "def dQ_ds(c, data):              \n",
    "    if c == 0:            \n",
    "        if np.sum(data) > tau_1:\n",
    "            data = 2 * data\n",
    "            return data\n",
    "    else:\n",
    "        if np.sum(data) < tau_2:\n",
    "            data = 2 * (data - 1)\n",
    "            return data\n",
    "    return data\n",
    "\n",
    "def ds_dl(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def dy_dp(y):\n",
    "    return y * (1 - y)\n",
    " \n",
    "output = []\n",
    "\n",
    "training = data[0:1960]\n",
    "\n",
    "# Iterations for training model\n",
    "for i in range(1000):      \n",
    "      \n",
    "    training = np.random.permutation(training)    \n",
    "    \n",
    "    for t in training:    \n",
    "        t2 = np.nan_to_num(t)\n",
    "        for u in t2:                                     \n",
    "            c = u[:, :][5][0]\n",
    "        \n",
    "            u2 = u[:5, :]\n",
    "        \n",
    "            # Net input of hidden layer\n",
    "            p = np.dot(u2, r)        \n",
    "            \n",
    "            # Activation of hidden layer\n",
    "            y = activate(p)\n",
    "            \n",
    "            # Chain of partial derivatives for Model 2               \n",
    "            \n",
    "            # Net input of output node\n",
    "            l = np.dot(y, w)        \n",
    "            \n",
    "            # Activation of output node\n",
    "            s = activate(l)   \n",
    "            \n",
    "            dE_o = dQ_ds(c, s)\n",
    "            \n",
    "            dE_h = np.dot(dE_o, w.T)\n",
    "            \n",
    "            dQ_dw = eta * np.dot(y.T, dE_o * ds_dl(s))\n",
    "                                 \n",
    "            dQ_dr = eta * np.dot(u2.T, dE_h * dy_dp(y))        \n",
    "            \n",
    "            r -= dQ_dr\n",
    "            w -= dQ_dw\n",
    "            \n",
    "            output.append([np.sum(s), c])\n",
    "             \n",
    "    \n",
    "    result = np.array([output])\n",
    "                        \n",
    "        \n",
    "    f = result\n",
    "    if len(f) > 0:              \n",
    "        f2 = result[:, :, 1] == 0\n",
    "        f3 = result[:, :, 1] == 1\n",
    "        f4 = result[:, :, 0] > 0.5\n",
    "        f5 = result[:, :, 0] < 0.5\n",
    "          \n",
    "        print(len(f[f2 & f4]), len(f[f3 & f5]))\n",
    "        \n",
    "    r_final = r\n",
    "    w_final = w\n",
    "        \n",
    "    output = []\n",
    "    result = []\n",
    "    #np.savetxt(\"training_output.txt\", np.array([output]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
