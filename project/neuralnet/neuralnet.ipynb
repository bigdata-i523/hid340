{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1432\n",
      "2 1184\n",
      "34 305\n",
      "61 188\n",
      "59 175\n",
      "70 160\n",
      "65 178\n",
      "46 207\n",
      "31 271\n",
      "30 243\n",
      "32 292\n",
      "34 236\n",
      "36 241\n",
      "28 259\n",
      "30 263\n",
      "28 273\n",
      "29 262\n",
      "26 291\n",
      "22 301\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87aeae60df64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m# Activation of output node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mdE_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdQ_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-87aeae60df64>\u001b[0m in \u001b[0;36mactivate\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Sigmoid activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Partial derivatives for output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  7 03:27:25 2017\n",
    "\n",
    "Based on the supervised gradident-based learning algorithm specified by \n",
    "Reyes-Galaviz et al. (2017).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_count = 8 \n",
    "hidden_count = 5\n",
    "output_count = 1\n",
    "\n",
    "eta = 0.06\n",
    "\n",
    "data = np.load(\"record_pairs.npy\", encoding=\"latin1\")\n",
    "data2 = np.nan_to_num(data)\n",
    "\n",
    "# Quality thresholds\n",
    "tau_1 = 0.01\n",
    "tau_2 = 0.99\n",
    "\n",
    "# The MLP model has 8 inputs and 5 nodes in the hidden layer. It follows \n",
    "# the Model 2 setup presented by Reyes-Galaviz et al. Hidden nodes aggregate\n",
    "# values calculated by running each of 8 comparison functions over 5 data\n",
    "# fields (date, ISBN, title, publisher, creator/contributor)\n",
    "r = np.random.randn(input_count, hidden_count)\n",
    "w = np.random.randn(hidden_count, output_count)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def activate(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "# Partial derivatives for output layer\n",
    "\n",
    "# MSE\n",
    "#def E_total(c, s):\n",
    "#    if c == 0:\n",
    "#        return 0.5 * np.sum(tau_1 - s)**2\n",
    "#    else:\n",
    "#        return 0.5 * np.sum(tau_2 - s)**2\n",
    "    \n",
    "#def dQ_ds(c, s):\n",
    "#    if c == 0:\n",
    "#        return -(tau_1 - np.sum(s))\n",
    "#    else:\n",
    "#        return -(tau_2 - np.sum(s))             \n",
    "    \n",
    "def dQ_ds(c, data):    \n",
    "    total = []\n",
    "    for d in data:            \n",
    "        if c == 0:\n",
    "            if np.sum(d) > tau_1:\n",
    "                d = 2 * d\n",
    "        else:\n",
    "            if np.sum(d) < tau_2:\n",
    "                d = 2 * (d - 1)\n",
    "        total.append(d)\n",
    "    return np.sum(total)\n",
    "\n",
    "def ds_dl(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def dy_dp(y):\n",
    "    return y * (1 - y)\n",
    " \n",
    "output = []\n",
    "\n",
    "training = data[0:1960]\n",
    "\n",
    "# Iterations for training model\n",
    "for i in range(1000):      \n",
    "      \n",
    "    training = np.random.permutation(training)    \n",
    "    \n",
    "    for t in training:    \n",
    "        t2 = np.nan_to_num(t)\n",
    "        for u in t2:                                     \n",
    "            c = u[:, :][5][0]\n",
    "        \n",
    "            u2 = u[:5, :]\n",
    "        \n",
    "            # Net input of hidden layer\n",
    "            p = np.dot(u2, r)        \n",
    "            \n",
    "            # Activation of hidden layer\n",
    "            y = activate(p)\n",
    "            \n",
    "            # Chain of partial derivatives for Model 2               \n",
    "            \n",
    "            # Net input of output node\n",
    "            l = np.dot(y, w)        \n",
    "            \n",
    "            # Activation of output node\n",
    "            s = activate(l)   \n",
    "            \n",
    "            dE_o = dQ_ds(c, s)\n",
    "            \n",
    "            dE_h = np.dot(dE_o, w.T)\n",
    "            \n",
    "            dQ_dw = eta * np.dot(y.T, dE_o * ds_dl(s))\n",
    "                                 \n",
    "            dQ_dr = eta * np.dot(u2.T, dE_h * dy_dp(y))        \n",
    "            \n",
    "            r -= dQ_dr\n",
    "            w -= dQ_dw\n",
    "            \n",
    "            output.append([np.sum(s), c])\n",
    "             \n",
    "    \n",
    "    result = np.array([output])\n",
    "                        \n",
    "        \n",
    "    f = result\n",
    "    if len(f) > 0:              \n",
    "        f2 = result[:, :, 1] == 0\n",
    "        f3 = result[:, :, 1] == 1\n",
    "        f4 = result[:, :, 0] > 0.5\n",
    "        f5 = result[:, :, 0] < 0.5\n",
    "          \n",
    "        print(len(f[f2 & f4]), len(f[f3 & f5]))\n",
    "        \n",
    "    r_final = r\n",
    "    w_final = w\n",
    "        \n",
    "    output = []\n",
    "    result = []\n",
    "    #np.savetxt(\"training_output.txt\", np.array([output]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
