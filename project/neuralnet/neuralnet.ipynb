{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 380\n",
      "59 360\n",
      "36 339\n",
      "40 347\n",
      "44 351\n",
      "38 333\n",
      "37 343\n",
      "37 339\n",
      "26 325\n",
      "37 328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a1e1a0c69c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tt434/anaconda3/lib/python3.6/site-packages/numpy/lib/type_check.py\u001b[0m in \u001b[0;36mnan_to_num\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miscomplex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mmaxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getmaxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tt434/anaconda3/lib/python3.6/site-packages/numpy/lib/type_check.py\u001b[0m in \u001b[0;36m_getmaxmin\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_getmaxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetlimits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetlimits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  7 03:27:25 2017\n",
    "\n",
    "Based on the supervised gradident-based learning algorithm specified by \n",
    "Reyes-Galaviz et al. (2017).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_count = 8 \n",
    "hidden_count = 5\n",
    "output_count = 1\n",
    "\n",
    "eta = 0.8\n",
    "\n",
    "data = np.load(\"record_pairs.npy\", encoding=\"latin1\")\n",
    "data2 = np.nan_to_num(data)\n",
    "\n",
    "# Quality thresholds\n",
    "tau_1 = 0.5\n",
    "tau_2 = 0.5\n",
    "\n",
    "# The MLP model has 8 inputs and 5 nodes in the hidden layer. It follows \n",
    "# the Model 2 setup presented by Reyes-Galaviz et al. Hidden nodes aggregate\n",
    "# values calculated by running each of 8 comparison functions over 5 data\n",
    "# fields (date, ISBN, title, publisher, creator/contributor)\n",
    "r = np.random.randn(input_count, hidden_count)\n",
    "w = np.random.randn(hidden_count, output_count)\n",
    "\n",
    "# Sigmoid activation function\n",
    "def activate(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "# Partial derivatives for output layer\n",
    "\n",
    "# MSE\n",
    "#def E_total(c, s):\n",
    "#    if c == 0:\n",
    "#        return 0.5 * np.sum(tau_1 - s)**2\n",
    "#    else:\n",
    "#        return 0.5 * np.sum(tau_2 - s)**2\n",
    "    \n",
    "#def dQ_ds(c, s):\n",
    "#    if c == 0:\n",
    "#        return -(tau_1 - np.sum(s))\n",
    "#    else:\n",
    "#        return -(tau_2 - np.sum(s))             \n",
    "    \n",
    "def dQ_ds(c, data):              \n",
    "    if c == 0:            \n",
    "        if np.sum(data) > tau_1:\n",
    "            data = 2 * data\n",
    "            return data\n",
    "    else:        \n",
    "        if np.sum(data) < tau_2:\n",
    "            data = 2 * (data - 1)\n",
    "            return data\n",
    "    return data\n",
    "\n",
    "def ds_dl(s):\n",
    "    return s * (1 - s)\n",
    "\n",
    "def dy_dp(y):\n",
    "    return y * (1 - y)\n",
    " \n",
    "output = []\n",
    "\n",
    "training = data[0:1960]\n",
    "\n",
    "# Iterations for training model\n",
    "for i in range(1000):      \n",
    "      \n",
    "    training = np.random.permutation(training)    \n",
    "    \n",
    "    for t in training:    \n",
    "        t2 = np.nan_to_num(t)\n",
    "        if t2.shape[0] != 0:\n",
    "            \n",
    "            for u in t2:                                     \n",
    "                c = u[:, :][5][0]\n",
    "            \n",
    "                u2 = u[:5, :]\n",
    "            \n",
    "                # Net input of hidden layer\n",
    "                p = np.dot(u2, r)        \n",
    "                \n",
    "                # Activation of hidden layer\n",
    "                y = activate(p)\n",
    "                \n",
    "                # Chain of partial derivatives for Model 2               \n",
    "                \n",
    "                # Net input of output node\n",
    "                l = np.dot(y, w)        \n",
    "                \n",
    "                # Activation of output node\n",
    "                s = activate(l)   \n",
    "                \n",
    "                dE_o = dQ_ds(c, s)\n",
    "                \n",
    "                dE_h = np.dot(dE_o, w.T)\n",
    "                \n",
    "                dQ_dw = eta * np.dot(y.T, dE_o * ds_dl(s))\n",
    "                                     \n",
    "                dQ_dr = eta * np.dot(u2.T, dE_h * dy_dp(y))        \n",
    "                \n",
    "                r -= dQ_dr\n",
    "                w -= dQ_dw\n",
    "                \n",
    "                output.append([np.sum(s), c])\n",
    "                \n",
    "                \n",
    "            result = np.array([output])\n",
    "           \n",
    "            \n",
    "            \n",
    "            f = result\n",
    "            if len(f) > 0:              \n",
    "                f2 = result[:, :, 1] == 0\n",
    "                f3 = result[:, :, 1] == 1\n",
    "                f4 = result[:, :, 0] > 0.5\n",
    "                f5 = result[:, :, 0] < 0.5\n",
    "                  \n",
    "                print(len(f[f2 & f4]), len(f[f3 & f5]))\n",
    "            \n",
    "        r_final = r\n",
    "        w_final = w\n",
    "            \n",
    "        output = []\n",
    "        result = []\n",
    "        #np.savetxt(\"training_output.txt\", np.array([output]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
